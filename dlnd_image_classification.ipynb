{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:33, 5.14MB/s]                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/cifar/cifar-10-python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN40TWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e7dbefe10>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return (x / 255.0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    color_channels = x_tensor.shape[3].value\n",
    "\n",
    "    weights_value = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], color_channels, conv_num_outputs], mean=0, stddev=0.1))\n",
    "\n",
    "    bias_value = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights_value, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    \n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias_value)\n",
    "    \n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "                          \n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "\n",
    "    return conv_layer\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    weights_value = tf.Variable(tf.random_normal([shape[-1], num_outputs], mean=0, stddev=0.1))\n",
    "    \n",
    "    biases_value = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    full_conv_layer = tf.add(tf.matmul(x_tensor, weights_value), biases_value)\n",
    "    \n",
    "    return tf.nn.relu(full_conv_layer)\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "           \n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    weights_value = tf.Variable(tf.random_normal([shape[-1], num_outputs], mean=0, stddev=0.1))\n",
    "    \n",
    "    biases_value = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weights_value), biases_value)\n",
    "    \n",
    "    return output_layer\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 16, (4, 4), (1, 1), (2, 2), (2, 2))\n",
    "    conv = conv2d_maxpool(x, 32, (4, 4), (1, 1), (2, 2), (2, 2))\n",
    "    conv = conv2d_maxpool(x, 64, (4, 4), (1, 1), (2, 2), (2, 2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_layer = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    f_con = fully_conn(flatten_layer, 512)\n",
    "    f_con = tf.nn.dropout(f_con, keep_prob)\n",
    "    f_con = fully_conn(f_con, 64)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out_layer = output(f_con, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss_value = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "\n",
    "    val_accuracy_value = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "\n",
    "    print('Loss value: {} Validation Accuracy: {}'.format(loss_value, val_accuracy_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss value: 2.069161891937256 Validation Accuracy: 0.30219998955726624\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss value: 1.7454532384872437 Validation Accuracy: 0.4016000032424927\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss value: 1.4241511821746826 Validation Accuracy: 0.47040000557899475\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss value: 1.1756725311279297 Validation Accuracy: 0.5109999775886536\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss value: 0.9361782073974609 Validation Accuracy: 0.5095999836921692\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss value: 0.719208836555481 Validation Accuracy: 0.5157999992370605\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss value: 0.5571790933609009 Validation Accuracy: 0.5401999950408936\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss value: 0.41359013319015503 Validation Accuracy: 0.5370000004768372\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss value: 0.3434489965438843 Validation Accuracy: 0.520799994468689\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss value: 0.24734830856323242 Validation Accuracy: 0.5339999794960022\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss value: 0.1553909033536911 Validation Accuracy: 0.5386000275611877\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss value: 0.1181710734963417 Validation Accuracy: 0.5230000019073486\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss value: 0.09066208451986313 Validation Accuracy: 0.5198000073432922\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss value: 0.06952519714832306 Validation Accuracy: 0.5419999957084656\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss value: 0.06747321784496307 Validation Accuracy: 0.5284000039100647\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss value: 0.0595320463180542 Validation Accuracy: 0.5442000031471252\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss value: 0.029023826122283936 Validation Accuracy: 0.5393999814987183\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss value: 0.028239810839295387 Validation Accuracy: 0.5419999957084656\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss value: 0.01811538077890873 Validation Accuracy: 0.5411999821662903\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss value: 0.01023793499916792 Validation Accuracy: 0.5526000261306763\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss value: 0.009588438086211681 Validation Accuracy: 0.5526000261306763\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss value: 0.011284951120615005 Validation Accuracy: 0.5447999835014343\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss value: 0.012883879244327545 Validation Accuracy: 0.5509999990463257\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss value: 0.00624800194054842 Validation Accuracy: 0.5509999990463257\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss value: 0.0037498660385608673 Validation Accuracy: 0.5582000017166138\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss value: 0.003296528710052371 Validation Accuracy: 0.5454000234603882\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss value: 0.006447814404964447 Validation Accuracy: 0.5478000044822693\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss value: 0.0035716728307306767 Validation Accuracy: 0.5464000105857849\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss value: 0.004509937949478626 Validation Accuracy: 0.5529999732971191\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss value: 0.0058097536675632 Validation Accuracy: 0.5415999889373779\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss value: 0.001516104442998767 Validation Accuracy: 0.5422000288963318\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss value: 0.0013588729780167341 Validation Accuracy: 0.5514000058174133\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss value: 0.0015794567298144102 Validation Accuracy: 0.5447999835014343\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss value: 0.0005990734207443893 Validation Accuracy: 0.5464000105857849\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss value: 0.0014132477808743715 Validation Accuracy: 0.5429999828338623\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss value: 0.0005337100592441857 Validation Accuracy: 0.555400013923645\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss value: 0.00105197390075773 Validation Accuracy: 0.5511999726295471\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss value: 0.0007040977943688631 Validation Accuracy: 0.5475999712944031\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss value: 0.0018051931401714683 Validation Accuracy: 0.5393999814987183\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss value: 0.0008178971474990249 Validation Accuracy: 0.5569999814033508\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss value: 0.0012195305898785591 Validation Accuracy: 0.5569999814033508\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss value: 0.00105100660584867 Validation Accuracy: 0.5590000152587891\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss value: 0.0012606186792254448 Validation Accuracy: 0.5464000105857849\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss value: 0.0016431469703093171 Validation Accuracy: 0.5508000254631042\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss value: 0.0009601851925253868 Validation Accuracy: 0.5468000173568726\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss value: 0.0010031734127551317 Validation Accuracy: 0.5442000031471252\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss value: 0.0005279171164147556 Validation Accuracy: 0.5522000193595886\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss value: 0.000950210727751255 Validation Accuracy: 0.5508000254631042\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss value: 0.0003726345603354275 Validation Accuracy: 0.5544000267982483\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss value: 0.0021785409189760685 Validation Accuracy: 0.5569999814033508\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss value: 2.002988338470459 Validation Accuracy: 0.31139999628067017\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss value: 1.518007516860962 Validation Accuracy: 0.42179998755455017\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss value: 1.3376045227050781 Validation Accuracy: 0.45399999618530273\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss value: 1.3358888626098633 Validation Accuracy: 0.49559998512268066\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss value: 1.2048289775848389 Validation Accuracy: 0.5332000255584717\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss value: 1.3957700729370117 Validation Accuracy: 0.5428000092506409\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss value: 0.9345188140869141 Validation Accuracy: 0.5640000104904175\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss value: 0.8498415946960449 Validation Accuracy: 0.5802000164985657\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss value: 0.9267160296440125 Validation Accuracy: 0.5979999899864197\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss value: 0.8446429967880249 Validation Accuracy: 0.6176000237464905\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss value: 0.964032769203186 Validation Accuracy: 0.5982000231742859\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss value: 0.6631865501403809 Validation Accuracy: 0.607200026512146\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss value: 0.5962337255477905 Validation Accuracy: 0.6164000034332275\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss value: 0.681536078453064 Validation Accuracy: 0.6344000101089478\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss value: 0.5721123814582825 Validation Accuracy: 0.628000020980835\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss value: 0.6924393773078918 Validation Accuracy: 0.629800021648407\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss value: 0.45530596375465393 Validation Accuracy: 0.6381999850273132\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss value: 0.3845505118370056 Validation Accuracy: 0.6388000249862671\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss value: 0.4629969000816345 Validation Accuracy: 0.6507999897003174\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss value: 0.4276573061943054 Validation Accuracy: 0.6421999931335449\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss value: 0.4471686780452728 Validation Accuracy: 0.6474000215530396\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss value: 0.30196845531463623 Validation Accuracy: 0.6488000154495239\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss value: 0.25438109040260315 Validation Accuracy: 0.6606000065803528\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss value: 0.3150120675563812 Validation Accuracy: 0.6565999984741211\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss value: 0.2640799880027771 Validation Accuracy: 0.6413999795913696\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss value: 0.3145768642425537 Validation Accuracy: 0.6552000045776367\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss value: 0.1880398839712143 Validation Accuracy: 0.6567999720573425\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss value: 0.17900757491588593 Validation Accuracy: 0.6498000025749207\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss value: 0.20218515396118164 Validation Accuracy: 0.6565999984741211\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss value: 0.19198045134544373 Validation Accuracy: 0.65420001745224\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss value: 0.20366820693016052 Validation Accuracy: 0.6674000024795532\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss value: 0.13466663658618927 Validation Accuracy: 0.6514000296592712\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss value: 0.15763501822948456 Validation Accuracy: 0.6161999702453613\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss value: 0.16526862978935242 Validation Accuracy: 0.6531999707221985\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss value: 0.12718896567821503 Validation Accuracy: 0.6592000126838684\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss value: 0.17420276999473572 Validation Accuracy: 0.6281999945640564\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss value: 0.09974926710128784 Validation Accuracy: 0.6266000270843506\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss value: 0.10873861610889435 Validation Accuracy: 0.6499999761581421\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss value: 0.10696599632501602 Validation Accuracy: 0.6502000093460083\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss value: 0.09700553119182587 Validation Accuracy: 0.6625999808311462\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss value: 0.08514474332332611 Validation Accuracy: 0.6607999801635742\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss value: 0.07467512786388397 Validation Accuracy: 0.635200023651123\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss value: 0.058820705860853195 Validation Accuracy: 0.6633999943733215\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss value: 0.09422612935304642 Validation Accuracy: 0.6385999917984009\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss value: 0.07513941079378128 Validation Accuracy: 0.6349999904632568\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss value: 0.0552530400454998 Validation Accuracy: 0.6567999720573425\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss value: 0.05429564788937569 Validation Accuracy: 0.6326000094413757\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss value: 0.026199597865343094 Validation Accuracy: 0.6525999903678894\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss value: 0.03513786941766739 Validation Accuracy: 0.6538000106811523\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss value: 0.052125364542007446 Validation Accuracy: 0.6327999830245972\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss value: 0.03737913444638252 Validation Accuracy: 0.651199996471405\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss value: 0.026076922193169594 Validation Accuracy: 0.6363999843597412\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss value: 0.030231887474656105 Validation Accuracy: 0.6507999897003174\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss value: 0.03593471646308899 Validation Accuracy: 0.6460000276565552\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss value: 0.025285566225647926 Validation Accuracy: 0.656000018119812\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss value: 0.02100295200943947 Validation Accuracy: 0.6439999938011169\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss value: 0.030831104144454002 Validation Accuracy: 0.6453999876976013\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss value: 0.01930568553507328 Validation Accuracy: 0.6489999890327454\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss value: 0.051216281950473785 Validation Accuracy: 0.6259999871253967\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss value: 0.020258907228708267 Validation Accuracy: 0.6600000262260437\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss value: 0.016842488199472427 Validation Accuracy: 0.6620000004768372\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss value: 0.02474258467555046 Validation Accuracy: 0.6583999991416931\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss value: 0.018006302416324615 Validation Accuracy: 0.6601999998092651\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss value: 0.02281695045530796 Validation Accuracy: 0.6439999938011169\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss value: 0.013744533061981201 Validation Accuracy: 0.6398000121116638\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss value: 0.013333359733223915 Validation Accuracy: 0.6697999835014343\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss value: 0.007847475819289684 Validation Accuracy: 0.6510000228881836\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss value: 0.008169636130332947 Validation Accuracy: 0.6535999774932861\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss value: 0.012618931010365486 Validation Accuracy: 0.650600016117096\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss value: 0.010571626015007496 Validation Accuracy: 0.6244000196456909\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss value: 0.006922341883182526 Validation Accuracy: 0.6600000262260437\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss value: 0.011611598543822765 Validation Accuracy: 0.6254000067710876\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss value: 0.004395253956317902 Validation Accuracy: 0.6547999978065491\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss value: 0.013293914496898651 Validation Accuracy: 0.6417999863624573\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss value: 0.006315093487501144 Validation Accuracy: 0.6507999897003174\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss value: 0.018280643969774246 Validation Accuracy: 0.646399974822998\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss value: 0.0036808685399591923 Validation Accuracy: 0.6516000032424927\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss value: 0.006358779035508633 Validation Accuracy: 0.657800018787384\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss value: 0.006049309857189655 Validation Accuracy: 0.6470000147819519\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss value: 0.008566392585635185 Validation Accuracy: 0.6435999870300293\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss value: 0.008505186066031456 Validation Accuracy: 0.6561999917030334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, CIFAR-10 Batch 2:  Loss value: 0.006764193065464497 Validation Accuracy: 0.6496000289916992\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss value: 0.008321818895637989 Validation Accuracy: 0.6517999768257141\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss value: 0.006739722099155188 Validation Accuracy: 0.6362000107765198\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss value: 0.0072145177982747555 Validation Accuracy: 0.6603999733924866\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss value: 0.009007959626615047 Validation Accuracy: 0.652999997138977\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss value: 0.007886306382715702 Validation Accuracy: 0.63919997215271\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss value: 0.00539009552448988 Validation Accuracy: 0.6539999842643738\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss value: 0.010318998247385025 Validation Accuracy: 0.6362000107765198\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss value: 0.0026987805031239986 Validation Accuracy: 0.6636000275611877\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss value: 0.005234886892139912 Validation Accuracy: 0.6517999768257141\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss value: 0.0075343213975429535 Validation Accuracy: 0.6388000249862671\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss value: 0.0023175040259957314 Validation Accuracy: 0.6610000133514404\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss value: 0.005223636981099844 Validation Accuracy: 0.6388000249862671\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss value: 0.0012164907529950142 Validation Accuracy: 0.6567999720573425\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss value: 0.0039347014389932156 Validation Accuracy: 0.6471999883651733\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss value: 0.0023257515858858824 Validation Accuracy: 0.6557999849319458\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss value: 0.0020131352357566357 Validation Accuracy: 0.6575999855995178\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss value: 0.0053281597793102264 Validation Accuracy: 0.6420000195503235\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss value: 0.0009140633046627045 Validation Accuracy: 0.6628000140190125\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss value: 0.0027648531831800938 Validation Accuracy: 0.6359999775886536\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss value: 0.0019326094770804048 Validation Accuracy: 0.6425999999046326\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss value: 0.007688296493142843 Validation Accuracy: 0.6592000126838684\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss value: 0.007129265461117029 Validation Accuracy: 0.6424000263214111\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss value: 0.0008728988468647003 Validation Accuracy: 0.6686000227928162\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss value: 0.0019187632715329528 Validation Accuracy: 0.6620000004768372\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss value: 0.0009273570030927658 Validation Accuracy: 0.6484000086784363\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss value: 0.004981509875506163 Validation Accuracy: 0.656000018119812\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss value: 0.011526424437761307 Validation Accuracy: 0.6488000154495239\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss value: 0.002665036590769887 Validation Accuracy: 0.6488000154495239\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss value: 0.0007511575822718441 Validation Accuracy: 0.6629999876022339\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss value: 0.0013015924487262964 Validation Accuracy: 0.6601999998092651\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss value: 0.0036291524302214384 Validation Accuracy: 0.6575999855995178\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss value: 0.0026316686999052763 Validation Accuracy: 0.6449999809265137\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss value: 0.003994943108409643 Validation Accuracy: 0.652999997138977\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss value: 0.0018905677134171128 Validation Accuracy: 0.6669999957084656\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss value: 0.0007617458468303084 Validation Accuracy: 0.6543999910354614\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss value: 0.0014725337969139218 Validation Accuracy: 0.6579999923706055\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss value: 0.007343186531215906 Validation Accuracy: 0.6444000005722046\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss value: 0.0015933249378576875 Validation Accuracy: 0.6521999835968018\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss value: 0.0031761061400175095 Validation Accuracy: 0.6462000012397766\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss value: 0.00029274015105329454 Validation Accuracy: 0.6448000073432922\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss value: 0.0020820724312216043 Validation Accuracy: 0.6478000283241272\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss value: 0.001022529206238687 Validation Accuracy: 0.6535999774932861\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss value: 0.00109950453042984 Validation Accuracy: 0.652999997138977\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss value: 0.0005968520999886096 Validation Accuracy: 0.6589999794960022\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss value: 0.0007681379793211818 Validation Accuracy: 0.6556000113487244\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss value: 0.0008350573480129242 Validation Accuracy: 0.6615999937057495\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss value: 0.002207950223237276 Validation Accuracy: 0.6520000100135803\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss value: 0.0068870545364916325 Validation Accuracy: 0.645799994468689\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss value: 0.0007646178128197789 Validation Accuracy: 0.6488000154495239\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss value: 0.000308117363601923 Validation Accuracy: 0.6593999862670898\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss value: 0.0010186501313000917 Validation Accuracy: 0.6628000140190125\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss value: 0.003201960353180766 Validation Accuracy: 0.6583999991416931\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss value: 0.0027190193068236113 Validation Accuracy: 0.651199996471405\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss value: 0.004289451986551285 Validation Accuracy: 0.6565999984741211\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss value: 0.0007652321946807206 Validation Accuracy: 0.6517999768257141\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss value: 0.000907176814507693 Validation Accuracy: 0.6603999733924866\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss value: 0.0018801670521497726 Validation Accuracy: 0.6528000235557556\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss value: 0.006426546722650528 Validation Accuracy: 0.6507999897003174\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss value: 0.0004678865079768002 Validation Accuracy: 0.650600016117096\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss value: 0.0013488514814525843 Validation Accuracy: 0.652400016784668\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss value: 0.0001594886853126809 Validation Accuracy: 0.6665999889373779\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss value: 0.005438960622996092 Validation Accuracy: 0.6549999713897705\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss value: 0.0006457922281697392 Validation Accuracy: 0.656000018119812\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss value: 0.0013054019073024392 Validation Accuracy: 0.6539999842643738\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss value: 0.0005386600969359279 Validation Accuracy: 0.6481999754905701\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss value: 0.0005458275554701686 Validation Accuracy: 0.6629999876022339\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss value: 0.0013182092225179076 Validation Accuracy: 0.6565999984741211\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss value: 0.0010315695544704795 Validation Accuracy: 0.6575999855995178\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss value: 0.001554996706545353 Validation Accuracy: 0.6571999788284302\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss value: 0.0013163686962798238 Validation Accuracy: 0.65420001745224\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss value: 0.0008382499217987061 Validation Accuracy: 0.6543999910354614\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss value: 0.0011924803256988525 Validation Accuracy: 0.650600016117096\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss value: 0.000563306559342891 Validation Accuracy: 0.6610000133514404\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss value: 0.006903288420289755 Validation Accuracy: 0.6460000276565552\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss value: 0.0006643278757110238 Validation Accuracy: 0.6593999862670898\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss value: 0.00022127351257950068 Validation Accuracy: 0.6583999991416931\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss value: 0.0012628245167434216 Validation Accuracy: 0.6503999829292297\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss value: 0.0005739391781389713 Validation Accuracy: 0.647599995136261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, CIFAR-10 Batch 1:  Loss value: 0.0005438221851363778 Validation Accuracy: 0.6525999903678894\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss value: 0.000654832343570888 Validation Accuracy: 0.657800018787384\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss value: 0.000428121245931834 Validation Accuracy: 0.6614000201225281\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss value: 0.0007465122034773231 Validation Accuracy: 0.6366000175476074\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss value: 0.0006622535292990506 Validation Accuracy: 0.656000018119812\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss value: 0.00025539036141708493 Validation Accuracy: 0.6593999862670898\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss value: 0.00154176726937294 Validation Accuracy: 0.6574000120162964\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss value: 0.0002502815914340317 Validation Accuracy: 0.657800018787384\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss value: 0.0006306481664068997 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss value: 0.00040490104584023356 Validation Accuracy: 0.6654000282287598\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss value: 0.0013937976909801364 Validation Accuracy: 0.6424000263214111\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss value: 0.0005399602232500911 Validation Accuracy: 0.6438000202178955\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss value: 0.00016910785052459687 Validation Accuracy: 0.6546000242233276\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss value: 0.0044880034402012825 Validation Accuracy: 0.6467999815940857\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss value: 0.00045665743527933955 Validation Accuracy: 0.6574000120162964\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss value: 0.005538513418287039 Validation Accuracy: 0.6484000086784363\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss value: 0.003402458503842354 Validation Accuracy: 0.652400016784668\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss value: 0.0014817094197496772 Validation Accuracy: 0.652400016784668\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss value: 0.0003852666704915464 Validation Accuracy: 0.6438000202178955\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss value: 0.0006921053281985223 Validation Accuracy: 0.6553999781608582\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss value: 0.002841751556843519 Validation Accuracy: 0.6502000093460083\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss value: 0.002720276126638055 Validation Accuracy: 0.6467999815940857\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss value: 0.00029444461688399315 Validation Accuracy: 0.6639999747276306\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss value: 0.0011385815450921655 Validation Accuracy: 0.6435999870300293\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss value: 0.0005653424886986613 Validation Accuracy: 0.6564000248908997\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss value: 0.00015371257904917002 Validation Accuracy: 0.6528000235557556\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss value: 0.0007477107574231923 Validation Accuracy: 0.6603999733924866\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss value: 0.00031471953843720257 Validation Accuracy: 0.6606000065803528\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss value: 0.0009684251854196191 Validation Accuracy: 0.6453999876976013\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss value: 0.0004347891954239458 Validation Accuracy: 0.6496000289916992\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss value: 0.00031611742451786995 Validation Accuracy: 0.6546000242233276\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss value: 0.00015098122821655124 Validation Accuracy: 0.6502000093460083\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss value: 9.984064672607929e-05 Validation Accuracy: 0.6611999869346619\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss value: 0.007375975139439106 Validation Accuracy: 0.6471999883651733\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss value: 0.009708957746624947 Validation Accuracy: 0.6425999999046326\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss value: 0.0007743037422187626 Validation Accuracy: 0.6567999720573425\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss value: 0.0014045319985598326 Validation Accuracy: 0.6425999999046326\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss value: 0.0004194862558506429 Validation Accuracy: 0.6575999855995178\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss value: 0.0003376443055458367 Validation Accuracy: 0.6607999801635742\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss value: 0.0009233705932274461 Validation Accuracy: 0.6435999870300293\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss value: 0.0007431523990817368 Validation Accuracy: 0.6492000222206116\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss value: 0.00011725869262591004 Validation Accuracy: 0.6556000113487244\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss value: 9.580868209013715e-05 Validation Accuracy: 0.6636000275611877\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss value: 0.003082514042034745 Validation Accuracy: 0.6442000269889832\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss value: 0.0012665638932958245 Validation Accuracy: 0.6557999849319458\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss value: 0.00025581492809578776 Validation Accuracy: 0.649399995803833\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss value: 5.2889408834744245e-05 Validation Accuracy: 0.6480000019073486\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss value: 0.0008171824738383293 Validation Accuracy: 0.6585999727249146\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss value: 0.00025675195502117276 Validation Accuracy: 0.6442000269889832\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss value: 0.0007177504012361169 Validation Accuracy: 0.6420000195503235\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss value: 0.00013054345618002117 Validation Accuracy: 0.6565999984741211\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss value: 3.916434434358962e-05 Validation Accuracy: 0.6539999842643738\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss value: 0.0001639559050090611 Validation Accuracy: 0.6570000052452087\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss value: 0.0003515274147503078 Validation Accuracy: 0.6474000215530396\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss value: 0.00011715006257873029 Validation Accuracy: 0.6492000222206116\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss value: 0.00017049578309524804 Validation Accuracy: 0.647599995136261\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss value: 0.00026270077796652913 Validation Accuracy: 0.6478000283241272\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss value: 0.00013817248691339046 Validation Accuracy: 0.657800018787384\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss value: 0.0007017083116807044 Validation Accuracy: 0.6556000113487244\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss value: 0.0012732645263895392 Validation Accuracy: 0.6547999978065491\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss value: 0.0005429729935713112 Validation Accuracy: 0.6507999897003174\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss value: 6.802735151723027e-05 Validation Accuracy: 0.6484000086784363\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss value: 0.00036988244391977787 Validation Accuracy: 0.6556000113487244\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss value: 0.0001565350394230336 Validation Accuracy: 0.6547999978065491\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss value: 0.0017435976769775152 Validation Accuracy: 0.6636000275611877\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss value: 0.00030260224593803287 Validation Accuracy: 0.6516000032424927\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss value: 0.00033376942155882716 Validation Accuracy: 0.6467999815940857\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss value: 0.0016875725705176592 Validation Accuracy: 0.6624000072479248\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss value: 0.00022303145669866353 Validation Accuracy: 0.6557999849319458\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss value: 0.0007182358531281352 Validation Accuracy: 0.6402000188827515\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss value: 0.00032568007009103894 Validation Accuracy: 0.6611999869346619\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss value: 0.0013961632503196597 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss value: 0.0009658772614784539 Validation Accuracy: 0.6460000276565552\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss value: 0.00017401925288140774 Validation Accuracy: 0.6534000039100647\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss value: 0.007658347487449646 Validation Accuracy: 0.6556000113487244\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss value: 0.00013636393123306334 Validation Accuracy: 0.6520000100135803\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss value: 4.626716690836474e-05 Validation Accuracy: 0.6488000154495239\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss value: 0.0002373394527239725 Validation Accuracy: 0.6686000227928162\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss value: 9.260598017135635e-05 Validation Accuracy: 0.6538000106811523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, CIFAR-10 Batch 5:  Loss value: 0.00020585194579325616 Validation Accuracy: 0.6498000025749207\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss value: 0.0012036883272230625 Validation Accuracy: 0.6547999978065491\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss value: 3.2005231332732365e-05 Validation Accuracy: 0.6474000215530396\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss value: 0.000541271991096437 Validation Accuracy: 0.6520000100135803\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss value: 4.7653338697273284e-05 Validation Accuracy: 0.6488000154495239\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss value: 0.0003142798668704927 Validation Accuracy: 0.6448000073432922\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss value: 0.0001245165040018037 Validation Accuracy: 0.6553999781608582\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss value: 6.45853069727309e-05 Validation Accuracy: 0.6549999713897705\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss value: 0.0001532155874883756 Validation Accuracy: 0.656000018119812\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss value: 0.0003765797009691596 Validation Accuracy: 0.6557999849319458\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss value: 0.00017889318405650556 Validation Accuracy: 0.6543999910354614\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6505142405063291\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKJEJ1pUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e033d12b0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
